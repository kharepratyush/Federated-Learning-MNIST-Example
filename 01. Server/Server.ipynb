{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-25T08:34:16.362134Z",
     "start_time": "2022-06-25T08:34:15.955639Z"
    }
   },
   "outputs": [],
   "source": [
    "from Server_Model import *\n",
    "from Server_Encryption import *\n",
    "from flask import Flask, json, request, render_template, session, redirect\n",
    "from flask import send_file\n",
    "from urllib.parse import urlparse\n",
    "import requests\n",
    "from cryptography.fernet import Fernet\n",
    "from random import randrange\n",
    "from flask import session, url_for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flask APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_available_clients():\n",
    "    \n",
    "    try:\n",
    "        with open(\"client.list\", \"r\") as f:\n",
    "            client_list = f.read()   \n",
    "    except:\n",
    "        client_list = \"\"\n",
    "        \n",
    "    client_list = client_list.split(\"\\n\")\n",
    "    \n",
    "    available_clients = []\n",
    "    for c in client_list:\n",
    "        r = requests.get(url = \"http://\"+c+'/active_test')\n",
    "    \n",
    "        #print(r, r.status_code, r.reason, r.text)\n",
    "        if r.status_code == 200:\n",
    "            #print(\"yeah\")\n",
    "            available_clients.append(c)\n",
    "            \n",
    "    return available_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-06-25T08:34:15.947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:10011/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 test samples\n",
      "['client_models_127.0.0.1_5000_agg_model.npy']\n",
      "client_models_127.0.0.1_5000_agg_model.npy\n",
      "Test loss: 0.0271899476647377\n",
      "Test accuracy: 0.9918000102043152\n",
      "Model written to storage!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pk15425\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n",
      "127.0.0.1 - - [14/Jul/2022 23:36:51] \"\u001b[37mGET /send_weights_to_clients HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [14/Jul/2022 23:38:38] \"\u001b[37mPOST /client_model HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"fname\": \"agg_model.npy\", \"url\": \"127.0.0.1\", \"port\": 5000, \"order_file\": \"order_file\"}'\n",
      "b'{\"0\": 1, \"1\": 0, \"2\": 3, \"3\": 7, \"4\": 2, \"5\": 5, \"6\": 6, \"7\": 4}'\n",
      "127.0.0.1_5000_agg_model.npy\n",
      "10000 test samples\n",
      "['client_models_127.0.0.1_5000_agg_model.npy']\n",
      "client_models_127.0.0.1_5000_agg_model.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [14/Jul/2022 23:38:49] \"\u001b[37mGET /send_weights_to_clients HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.03229633718729019\n",
      "Test accuracy: 0.9911999702453613\n",
      "Model written to storage!\n"
     ]
    }
   ],
   "source": [
    "api = Flask(__name__)\n",
    "\n",
    "\n",
    "@api.route('/', methods=['GET'])\n",
    "def get_landing_page():\n",
    "    \n",
    "    try:\n",
    "        with open(\"client.list\", \"r\") as f:\n",
    "            client_list = f.read()   \n",
    "    except:\n",
    "        client_list = \"\"\n",
    "        \n",
    "    client_list = client_list.split(\"\\n\")\n",
    "    if len(client_list) > 0:\n",
    "        return render_template('ServerLanding.html', list_clients=list(client_list))\n",
    "    return \"No clients\"\n",
    "\n",
    "@api.route('/register', methods=['GET'])\n",
    "def register_client():\n",
    "    \n",
    "    port = request.args.get('port')\n",
    "    url = request.args.get('url')\n",
    "    \n",
    "    try:\n",
    "        with open(\"client.list\", \"r\") as f:\n",
    "            client_list = f.read()   \n",
    "    except:\n",
    "        client_list = \"\"\n",
    "        \n",
    "    client_list = client_list.split(\"\\n\")\n",
    "    client_list.append(url + \":\" + port)\n",
    "    client_list = list(set(client_list))\n",
    "    client_list = '\\n'.join(str(x) for x in client_list)\n",
    "    \n",
    "    with open(\"client.list\", \"w\") as f:\n",
    "        f.write(client_list.strip())\n",
    "    \n",
    "    serverack = {'server_ack': '1'}\n",
    "    return str(serverack)\n",
    "\n",
    "\n",
    "@api.route('/send_weights_to_clients', methods=['GET'])\n",
    "def send_weights_to_clients():\n",
    "    \n",
    "    model_aggregation()\n",
    "    clients = check_available_clients()\n",
    "    order_file_path, file_name = encrypt_file('agg_model.npy')\n",
    "    \n",
    "    with open('filekey.key', 'rb') as filekey:\n",
    "        key = filekey.read()\n",
    "\n",
    "    fernet = Fernet(key)\n",
    "    with open(order_file_path, 'rb') as r:\n",
    "        data = r.read()\n",
    "        \n",
    "    data = fernet.encrypt(data = data)\n",
    "    \n",
    "    with open(order_file_path, 'wb+') as w:\n",
    "        w.write(data)\n",
    "        \n",
    "    file = open(file_name, 'rb')\n",
    "    order_file = open(order_file_path, 'rb')\n",
    "    \n",
    "#     with open('filekey.key', 'rb') as filekey:\n",
    "        \n",
    "    \n",
    "    data = {'fname':'agg_model.npy', 'order_file':'order_file'}\n",
    "    files = {\n",
    "        'json': ('json_data', json.dumps(data), 'application/json'),\n",
    "        'model': ('agg_model.npy', file, 'application/octet-stream'),\n",
    "        'order_file': ('order_file', order_file, 'application/octet-stream')\n",
    "    }\n",
    "    \n",
    "    for c in clients:\n",
    "        try:\n",
    "            req = requests.post(url=\"http://\"+c+'/downloadmodel', files=files)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    file.close()\n",
    "    order_file.close()\n",
    "    os.remove(order_file_path)\n",
    "    os.remove(file_name)\n",
    "    \n",
    "    return \"Aggregated model sent !\"\n",
    "\n",
    "@api.route('/client_model', methods=['POST'])\n",
    "def getmodel():\n",
    "    if request.method == 'POST':\n",
    "        file = request.files['model'].read()\n",
    "        order_file = request.files['order_file'].read()\n",
    "        data = request.files['json'].read()\n",
    "        print(data)\n",
    "        \n",
    "        with open('filekey.key', 'rb') as filekey:\n",
    "            key = filekey.read()\n",
    "        \n",
    "        fernet = Fernet(key)\n",
    "        order_file = fernet.decrypt(order_file)\n",
    "        print(order_file)\n",
    "        data = ast.literal_eval(data.decode(\"utf-8\"))\n",
    "\n",
    "        order_file_name = data['order_file']\n",
    "        cli = data['url']+'_' + str(data['port'])\n",
    "        fname = cli +\"_\" + data['fname']\n",
    "\n",
    "        print(fname)\n",
    "        wfile = open(\"client_models_\"+fname, 'wb+')\n",
    "        wfile.write(file)\n",
    "        wfile.close()\n",
    "        \n",
    "        wfile = open(\"client_models_\"+order_file_name, 'wb+')\n",
    "        wfile.write(order_file)\n",
    "        wfile.close()\n",
    "        \n",
    "        decrypt_file('client_models_'+fname, 'client_models_'+order_file_name)  \n",
    "        os.remove('client_models_'+order_file_name)\n",
    "        \n",
    "        return \"Model received!\"\n",
    "    else:\n",
    "        return \"No file received!\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    api.secret_key = randrange(100000)\n",
    "    api.config['SESSION_TYPE'] = 'filesystem'\n",
    "    api.config.update(\n",
    "        SESSION_COOKIE_NAME = 'session_server',\n",
    "        SESSION_COOKIE_PATH = '/server/'\n",
    "    )\n",
    "    api.run(port=10011)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
